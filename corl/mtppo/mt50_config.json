{
    "algo": "PPO",
    "meta_batch_size": 40,
    "hidden_sizes": [
      400,
      400,
      400
    ],
    "envs_per_task": 1,
    "rollouts_per_meta_task": 10,
    "parallel": true,
    "max_path_length":150,
    "discount": 0.99,
    "gae_lambda": 1.0,
    "init_std": 2.0,
    "normalize_adv": true,
    "positive_adv": false,
    "learning_rate": 1e-3,
    "learn_std": true,
    "max_epochs": 5,
    "n_itr": 1000000
}
